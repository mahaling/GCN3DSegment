{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2Fj4S3r0p1A"
   },
   "source": [
    "##### Copyright 2019 Google LLC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Okg-R95R1CaX"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4v1coMcWtiJ"
   },
   "source": [
    "# Mesh Segmentation using Feature Steered Graph Convolutions\n",
    "\n",
    "Segmenting a mesh to its semantic parts is an important problem for 3D shape\n",
    "understanding. This colab demonstrates how to build a semantic mesh segmentation\n",
    "model for deformable shapes using graph convolution layers defined in\n",
    "[Tensorflow Graphics](https://github.com/tensorflow/graphics).\n",
    "\n",
    "![](https://storage.googleapis.com/tensorflow-graphics/notebooks/mesh_segmentation/mesh_segmentation_demo.png)\n",
    "\n",
    "This notebook covers the following key topics:\n",
    "* How to use graph-convolutional layers to define a CNN for mesh segmentation.\n",
    "* How to setup a data pipeline torepresent mesh connectivity with SparseTensors.\n",
    "\n",
    "Note: The easiest way to use this tutorial is as a Colab notebook, which allows\n",
    "you to dive in with no setup.\n",
    "\n",
    "### Image Convolutions vs Graph Convolutions\n",
    "\n",
    "Images are represented by uniform grids of pixels. Running convolutions on\n",
    "uniform grids is a well understood process and is at the core of a significant\n",
    "amount of products and academic publications.\n",
    "![](https://storage.googleapis.com/tensorflow-graphics/notebooks/mesh_segmentation/cat_image_convolutions.png)\n",
    "\n",
    "However, things become a bit more complicated when dealing with three\n",
    "dimensional objects such as meshes or point clouds since these are not defined\n",
    "on regular grids. A convolution operation for meshes or point clouds must\n",
    "operate on irregular data structures. This makes convolutional neural\n",
    "networks based on them harder to implement.\n",
    "![](https://storage.googleapis.com/tensorflow-graphics/notebooks/mesh_segmentation/cat_mesh_convolutions.png)\n",
    "\n",
    "Any general mesh can be denoted as a graph that is not constrained to a regular grid. Many graph-convolutional operators have been published in\n",
    "the recent years. In this demo we use the method described in\n",
    "[Feature Steered Graph Convolutions](https://arxiv.org/abs/1706.05206). Similar\n",
    "to it's image counterpart, this basic building block can be used do solve a\n",
    "plethora of problems. This Colab focusses on segmenting deformable meshes of\n",
    "human bodies into parts (e.g. head, right foot, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNQ29y8Q4_cH"
   },
   "source": [
    "## Setup & Imports\n",
    "\n",
    "To run this Colab optimally, please update the runtime type to use a GPU\n",
    "hardware accelerator. - click on the 'Runtime' menu, then 'Change runtime type':\n",
    "\n",
    "![](https://storage.googleapis.com/tensorflow-graphics/notebooks/non_rigid_deformation/change_runtime.jpg)\n",
    "\n",
    "-   finally, set the 'Hardware accelerator' to 'GPU'.\n",
    "\n",
    "![](https://storage.googleapis.com/tensorflow-graphics/notebooks/mesh_segmentation/gpu_runtime.png)\n",
    "\n",
    "If Tensorflow Graphics is not installed on your system, the following cell will\n",
    "install the Tensorflow Graphics package for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UkPKOuyJKuKM"
   },
   "source": [
    "Now that Tensorflow Graphics and dependencies are installed, let's import everything needed to run the demos contained in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlBviBxue7n0"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_graphics.nn.layer import graph_convolution as graph_conv\n",
    "from tensorflow_graphics.notebooks import mesh_segmentation_dataio as dataio\n",
    "from tensorflow_graphics.notebooks import mesh_viewer\n",
    "%load_ext tensorboard\n",
    "\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from mesh_viewer import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_graphics.geometry.convolution import utils as conv_utils\n",
    "from tensorflow_graphics.geometry.representation.mesh import utils as mesh_utils\n",
    "from tensorflow_graphics.util import shape\n",
    "\n",
    "DEFAULT_IO_PARAMS = {\n",
    "    'batch_size': 8,\n",
    "    'shuffle_buffer_size': 100,\n",
    "    'is_training': True,\n",
    "    'parallel_threads': 5,\n",
    "    'mean_center': True,\n",
    "    'shuffle': None,\n",
    "    'repeat': None,\n",
    "}\n",
    "\n",
    "\n",
    "def adjacency_from_edges(edges, weights, num_edges, num_vertices):\n",
    "  \"\"\"Returns a batched sparse 1-ring adj tensor from edge list tensor.\n",
    "  Args:\n",
    "    edges: [B, E, 2] `int32` tensor of edges, possibly 0 padded.\n",
    "    weights: [B, E] `float32` tensor of edge weights, possibly 0 padded.\n",
    "    num_edges: [B] `int32` tensor of number of valid edges per batch sample.\n",
    "    num_vertices: [B] `int32` tensor of number of valid vertices per batch\n",
    "      sample.\n",
    "  Returns:\n",
    "    adj: A batched SparseTensor of weighted adjacency graph, of\n",
    "      dense_shape [B, V, V] where V is max(num_vertices)\n",
    "  \"\"\"\n",
    "  edges = tf.convert_to_tensor(value=edges)\n",
    "  weights = tf.convert_to_tensor(value=weights)\n",
    "  num_edges = tf.convert_to_tensor(value=num_edges)\n",
    "  num_vertices = tf.convert_to_tensor(value=num_vertices)\n",
    "\n",
    "  if not edges.dtype.is_integer:\n",
    "    raise TypeError(\"'edges' must have an integer type.\")\n",
    "  if not num_edges.dtype.is_integer:\n",
    "    raise TypeError(\"'num_edges' must have an integer type.\")\n",
    "  if not num_vertices.dtype.is_integer:\n",
    "    raise TypeError(\"'num_vertices' must have an integer type.\")\n",
    "  if not weights.dtype.is_floating:\n",
    "    raise TypeError(\"'weights' must have a floating type.\")\n",
    "\n",
    "  shape.check_static(tensor=edges, tensor_name='edges', has_rank=3)\n",
    "  shape.check_static(tensor=weights, tensor_name='weights', has_rank=2)\n",
    "  shape.check_static(tensor=num_edges, tensor_name='num_edges', has_rank=1)\n",
    "  shape.check_static(\n",
    "      tensor=num_vertices, tensor_name='num_vertices', has_rank=1)\n",
    "  shape.compare_dimensions(\n",
    "      tensors=(edges, weights, num_edges, num_vertices),\n",
    "      tensor_names=('edges', 'weights', 'num_edges', 'num_vertices'),\n",
    "      axes=(-3, -2, -1, -1))\n",
    "  shape.compare_dimensions(\n",
    "      tensors=(edges, weights),\n",
    "      tensor_names=('edges', 'weights'),\n",
    "      axes=(-2, -1))\n",
    "\n",
    "  batch_size = tf.shape(input=edges)[0]\n",
    "  max_num_vertices = tf.reduce_max(input_tensor=num_vertices)\n",
    "  max_num_edges = tf.shape(input=edges)[1]\n",
    "  batch_col = tf.reshape(tf.range(batch_size, dtype=edges.dtype), [-1, 1, 1])\n",
    "  batch_col = tf.tile(batch_col, [1, max_num_edges, 1])\n",
    "  batch_edges = tf.concat([batch_col, edges], axis=-1)\n",
    "\n",
    "  indices, _ = conv_utils.flatten_batch_to_2d(batch_edges, sizes=num_edges)\n",
    "  values, _ = conv_utils.flatten_batch_to_2d(\n",
    "      tf.expand_dims(weights, -1), sizes=num_edges)\n",
    "  values = tf.squeeze(values)\n",
    "  adjacency = tf.SparseTensor(\n",
    "      indices=tf.cast(indices, tf.int64),\n",
    "      values=values,\n",
    "      dense_shape=[batch_size, max_num_vertices, max_num_vertices])\n",
    "  adjacency = tf.sparse.reorder(adjacency)\n",
    "  return adjacency\n",
    "\n",
    "\n",
    "def get_weighted_edges(faces, self_edges=True):\n",
    "  r\"\"\"Gets unique edges and degree weights from a triangular mesh.\n",
    "  The shorthands used below are:\n",
    "      `T`: The number of triangles in the mesh.\n",
    "      `E`: The number of unique directed edges in the mesh.\n",
    "  Args:\n",
    "    faces: A [T, 3] `int32` numpy.ndarray of triangle vertex indices.\n",
    "    self_edges: A `bool` flag. If true, then for every vertex 'i' an edge\n",
    "      [i, i] is added to edge list.\n",
    "  Returns:\n",
    "    edges: A  [E, 2] `int32` numpy.ndarray of directed edges.\n",
    "    weights: A [E] `float32` numpy.ndarray denoting edge weights.\n",
    "    The degree of a vertex is the number of edges incident on the vertex,\n",
    "    including any self-edges. The weight for an edge $w_{ij}$ connecting vertex\n",
    "    $v_i$ and vertex $v_j$ is defined as,\n",
    "    $$\n",
    "    w_{ij} = 1.0 / degree(v_i)\n",
    "    \\sum_{j} w_{ij} = 1\n",
    "    $$\n",
    "  \"\"\"\n",
    "  edges = mesh_utils.extract_unique_edges_from_triangular_mesh(\n",
    "      faces, directed_edges=True).astype(np.int32)\n",
    "  if self_edges:\n",
    "    vertices = np.expand_dims(np.unique(edges[:, 0]), axis=1)\n",
    "    self_edges = np.concatenate((vertices, vertices), axis=1)\n",
    "    edges = np.unique(np.concatenate((edges, self_edges), axis=0), axis=0)\n",
    "  weights = mesh_utils.get_degree_based_edge_weights(edges, dtype=np.float32)\n",
    "  return edges, weights\n",
    "\n",
    "\n",
    "def _tfrecords_to_dataset(tfrecords,\n",
    "                          parallel_threads,\n",
    "                          shuffle,\n",
    "                          repeat,\n",
    "                          sloppy,\n",
    "                          max_readers=16):\n",
    "  \"\"\"Creates a TFRecordsDataset that iterates over filenames in parallel.\n",
    "  Args:\n",
    "    tfrecords: A list of tf.Data.TFRecords filenames.\n",
    "    parallel_threads: The `int` number denoting number of parallel worker\n",
    "      threads.\n",
    "    shuffle: The `bool` flag denoting whether to shuffle the dataset.\n",
    "    repeat: The `bool` flag denoting whether to repeat the dataset.\n",
    "    sloppy: The `bool` flag denoting if elements are produced in deterministic\n",
    "      order.\n",
    "    max_readers: The `int` number denoting the maximum number of input tfrecords\n",
    "      to interleave from in parallel.\n",
    "  Returns:\n",
    "    A tf.data.TFRecordDataset\n",
    "  \"\"\"\n",
    "\n",
    "  total_tfrecords = sum([len(tf.io.gfile.glob(f)) for f in tfrecords])\n",
    "  num_readers = min(total_tfrecords, max_readers)\n",
    "  dataset = tf.data.Dataset.list_files(tfrecords, shuffle=shuffle)\n",
    "  if repeat:\n",
    "    dataset = dataset.repeat()\n",
    "  return dataset.apply(\n",
    "      tf.data.experimental.parallel_interleave(\n",
    "          tf.data.TFRecordDataset,\n",
    "          num_readers,\n",
    "          sloppy=sloppy,\n",
    "          buffer_output_elements=parallel_threads,\n",
    "          prefetch_input_elements=parallel_threads))\n",
    "\n",
    "\n",
    "def _parse_tfex_proto(example_proto):\n",
    "  \"\"\"Parses the tfexample proto to a raw mesh_data dictionary.\n",
    "  Args:\n",
    "    example_proto: A tf.Example proto storing the encoded mesh data.\n",
    "  Returns:\n",
    "    A mesh data dictionary with the following fields:\n",
    "      'num_vertices': The `int64` number of vertices in mesh.\n",
    "      'num_triangles': The `int64` number of triangles in mesh.\n",
    "      'vertices': A serialized tensor of vertex positions.\n",
    "      'triangles': A serialized tensor of triangle vertex indices.\n",
    "      'labels': A serialized tensor of per vertex class labels.\n",
    "  \"\"\"\n",
    "  feature_description = {\n",
    "      'num_vertices': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "      'num_triangles': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "      'vertices': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "      'triangles': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "      'labels': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "  }\n",
    "  return tf.io.parse_single_example(\n",
    "      serialized=example_proto, features=feature_description)\n",
    "\n",
    "\n",
    "def _parse_mesh_data(mesh_data, mean_center=True):\n",
    "  \"\"\"Parses a raw mesh_data dictionary read from tf examples.\n",
    "  Args:\n",
    "    mesh_data: A mesh data dictionary with serialized data tensors,\n",
    "      as output from _parse_tfex_proto()\n",
    "    mean_center: If true, centers the mesh vertices to mean(vertices).\n",
    "  Returns:\n",
    "     A mesh data dictionary with following fields:\n",
    "      'num_vertices': The `int32` number of vertices in mesh.\n",
    "      'num_triangles': The `int32` number of triangles in mesh.\n",
    "      'num_edges': The `int32` number of unique directed edges in mesh.\n",
    "      'vertices': A [V, 3] `float32` of vertex positions.\n",
    "      'triangles': A [T, 3] `int32` tensor of triangle vertex indices.\n",
    "      'labels': A [V] `int32` tensor of per vertex class labels.\n",
    "      'edges': A [E, 2] `int32` tensor of unique directed edges in mesh.\n",
    "      'edge_weights': A [E] `float32` tensor of vertex degree based edge\n",
    "        weights.\n",
    "  \"\"\"\n",
    "  labels = tf.io.parse_tensor(mesh_data['labels'], tf.int32)\n",
    "  vertices = tf.io.parse_tensor(mesh_data['vertices'], tf.float32)\n",
    "  triangles = tf.io.parse_tensor(mesh_data['triangles'], tf.int32)\n",
    "  if mean_center:\n",
    "    vertices = vertices - tf.reduce_mean(\n",
    "        input_tensor=vertices, axis=0, keepdims=True)\n",
    "\n",
    "  edges, weights = tf.py_function(\n",
    "      func=lambda t: get_weighted_edges(t.numpy()),\n",
    "      inp=[triangles],\n",
    "      Tout=[tf.int32, tf.float32])\n",
    "\n",
    "  num_edges = tf.shape(input=edges)[0]\n",
    "  num_vertices = tf.cast(mesh_data['num_vertices'], tf.int32)\n",
    "  num_triangles = tf.cast(mesh_data['num_triangles'], tf.int32)\n",
    "  mesh_data = dict(\n",
    "      vertices=vertices,\n",
    "      labels=labels,\n",
    "      triangles=triangles,\n",
    "      edges=edges,\n",
    "      edge_weights=weights,\n",
    "      num_triangles=num_triangles,\n",
    "      num_vertices=num_vertices,\n",
    "      num_edges=num_edges)\n",
    "  return mesh_data\n",
    "\n",
    "\n",
    "def create_dataset_from_tfrecords(tfrecords, params):\n",
    "  \"\"\"Creates a mesh dataset given a list of tf records filenames.\n",
    "  Args:\n",
    "    tfrecords: A list of TFRecords filenames.\n",
    "    params: A dictionary of IO paramaters, see DEFAULT_IO_PARAMS.\n",
    "  Returns:\n",
    "    A tf.data.Dataset, with each element a dictionary of batched mesh data\n",
    "      with following fields:\n",
    "      'vertices': A [B, V, 3] `float32` tensor of vertex positions, possibly\n",
    "        0-padded.\n",
    "      'triangles': A [B, T, 3] `int32` tensor of triangle vertex indices,\n",
    "        possibly 0-padded\n",
    "      'labels': A [B, V] `int32` tensor of per vertex class labels, possibly\n",
    "        0-padded\n",
    "      'edges': A [B, E, 2] `int32` tensor of unique directed edges in mesh,\n",
    "        possibly 0-padded\n",
    "      'edge_weights': A [B, E] `float32` tensor of vertex degree based edge\n",
    "        weights, possibly 0-padded.\n",
    "      'num_edges': A [B] `int32` tensor of number of unique directed edges in\n",
    "        each mesh in the batch.\n",
    "      'num_vertices':  A [B] `int32` tensor of number of vertices in each mesh\n",
    "        in the batch.\n",
    "      'num_triangles': A [B] `int32` tensor of number of triangles in each mesh\n",
    "        in the batch.\n",
    "  \"\"\"\n",
    "\n",
    "  def _set_default_if_none(param, param_dict, default_val):\n",
    "    if param not in param_dict:\n",
    "      return default_val\n",
    "    else:\n",
    "      return default_val if param_dict[param] is None else param_dict[param]\n",
    "\n",
    "  is_training = params['is_training']\n",
    "  shuffle = _set_default_if_none('shuffle', params, is_training)\n",
    "  repeat = _set_default_if_none('repeat', params, is_training)\n",
    "  sloppy = _set_default_if_none('sloppy', params, is_training)\n",
    "\n",
    "  if not isinstance(tfrecords, list):\n",
    "    tfrecords = [tfrecords]\n",
    "  dataset = _tfrecords_to_dataset(tfrecords, params['parallel_threads'],\n",
    "                                  shuffle, repeat, sloppy)\n",
    "  dataset = dataset.map(_parse_tfex_proto, tf.data.experimental.AUTOTUNE)\n",
    "  dataset = dataset.map(\n",
    "      lambda x: _parse_mesh_data(x, mean_center=params['mean_center']),\n",
    "      tf.data.experimental.AUTOTUNE)\n",
    "  if repeat:\n",
    "    dataset = dataset.repeat()\n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(params['shuffle_buffer_size'])\n",
    "  return dataset.padded_batch(\n",
    "      params['batch_size'],\n",
    "      padded_shapes={\n",
    "          'vertices': [None, 3],\n",
    "          'labels': [None],\n",
    "          'triangles': [None, 3],\n",
    "          'edges': [None, 2],\n",
    "          'edge_weights': [None],\n",
    "          'num_edges': [],\n",
    "          'num_vertices': [],\n",
    "          'num_triangles': [],\n",
    "      },\n",
    "      drop_remainder=is_training)\n",
    "\n",
    "\n",
    "def create_input_from_dataset(dataset_fn, files, io_params):\n",
    "  \"\"\"Creates input function given dataset generator and input files.\n",
    "  Args:\n",
    "    dataset_fn: A dataset generator function.\n",
    "    files: A list of TFRecords filenames.\n",
    "    io_params: A dictionary of IO paramaters, see DEFAULT_IO_PARAMS.\n",
    "  Returns:\n",
    "    features: A dictionary of mesh data training features.\n",
    "    labels: A [B] `int32` tensor of per vertex class labels.\n",
    "  \"\"\"\n",
    "  for k in DEFAULT_IO_PARAMS:\n",
    "    io_params[k] = io_params[k] if k in io_params else DEFAULT_IO_PARAMS[k]\n",
    "\n",
    "  dataset = dataset_fn(files, io_params)\n",
    "  mesh_data = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "  mesh_data['neighbors'] = adjacency_from_edges(mesh_data['edges'],\n",
    "                                                mesh_data['edge_weights'],\n",
    "                                                mesh_data['num_edges'],\n",
    "                                                mesh_data['num_vertices'])\n",
    "\n",
    "  max_num_verts = tf.reduce_max(input_tensor=mesh_data['num_vertices'])\n",
    "  features = dict(\n",
    "      vertices=tf.reshape(mesh_data['vertices'], [-1, max_num_verts, 3]),\n",
    "      triangles=mesh_data['triangles'],\n",
    "      neighbors=mesh_data['neighbors'],\n",
    "      edges=mesh_data['edges'],\n",
    "      edge_weights=mesh_data['edge_weights'],\n",
    "      num_triangles=mesh_data['num_triangles'],\n",
    "      num_vertices=mesh_data['num_vertices'],\n",
    "      extra=tf.shape(mesh_data['vertices'])\n",
    "  )\n",
    "  labels = mesh_data['labels']\n",
    "  # Copy labels to features dictionary for estimator prediction mode.\n",
    "  if not io_params['is_training']:\n",
    "    features['labels'] = mesh_data['labels']\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGaDtH49dlJb"
   },
   "source": [
    "Note this notebook works best in Graph mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Gh-ZSwXnB-5"
   },
   "source": [
    "### Fetch model files and data\n",
    "\n",
    "For convenience, we provide a pre-trained model. Let's now download a pre-trained model checkpoint and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZkB3iIcvvzJ"
   },
   "outputs": [],
   "source": [
    "# path_to_model_zip = tf.keras.utils.get_file(\n",
    "#     'model.zip',\n",
    "#     origin='https://storage.googleapis.com/tensorflow-graphics/notebooks/mesh_segmentation/model.zip',\n",
    "#     extract=True)\n",
    "\n",
    "# path_to_data_zip = tf.keras.utils.get_file(\n",
    "#     'data.zip',\n",
    "#     origin='https://storage.googleapis.com/tensorflow-graphics/notebooks/mesh_segmentation/data.zip',\n",
    "#     extract=True)\n",
    "\n",
    "# local_model_dir = os.path.join(os.path.dirname(path_to_model_zip), 'model')\n",
    "# test_data_files = [\n",
    "#     os.path.join(\n",
    "#         os.path.dirname(path_to_data_zip),\n",
    "#         'data/Dancer_test_sequence.tfrecords')\n",
    "# ]\n",
    "\n",
    "test_data_files = ['Dancer_test_sequence.tfrecords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmh4b6VKcATt"
   },
   "source": [
    "## Load and visualize test data\n",
    "\n",
    "For graph convolutions, we need a *weighted adjacency matrix* denoting the mesh\n",
    "connectivity. Feature-steered graph convolutions expect self-edges in the mesh\n",
    "connectivity for each vertex, i.e. the diagonal of the weighted adjacency matrix\n",
    "should be non-zero. This matrix is defined as:\n",
    "```\n",
    "A[i, j] = w[i,j] if vertex i and vertex j share an edge,\n",
    "A[i, i] = w[i,i] for each vertex i,\n",
    "A[i, j] = 0 otherwise.\n",
    "where, w[i, j] = 1/(degree(vertex i)), and sum(j)(w[i,j]) = 1\n",
    "```\n",
    "Here degree(vertex i) is the number of edges incident on a vertex (including the\n",
    "self-edge). This weighted adjacency matrix is stored as a SparseTensor.\n",
    "\n",
    "We will load the test meshes from the test [tf.data.TFRecordDataset](https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset)\n",
    "downloaded above. Each mesh is stored as a\n",
    "[tf.Example](https://www.tensorflow.org/api_docs/python/tf/train/Example), with\n",
    "the following fields:\n",
    "\n",
    "*   'num_vertices': Number of vertices in each mesh\n",
    "*   'num_triangles': Number of triangles in each mesh.\n",
    "*   'vertices': A [V, 3] float tensor of vertex positions.\n",
    "*   'triangles': A [T, 3] integer tensor of vertex indices for each triangle.\n",
    "*   'labels': A [V] integer tensor with segmentation class label for each\n",
    "    vertex.\n",
    "\n",
    "where 'V' is number of vertices and 'T' is number of triangles in the mesh. As\n",
    "each mesh may have a varying number of vertices and faces (and the corresponding\n",
    "connectivity matrix), we pad the data tensors with '0's in each batch.\n",
    "\n",
    "For details on the dataset pipeline implementation, take a look at\n",
    "mesh_segmentation_dataio.py.\n",
    "\n",
    "Lets try to load a batch from the test TFRecordDataset, and visualize the first\n",
    "mesh with each vertex colored by the part label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZM02o0pEny6"
   },
   "outputs": [],
   "source": [
    "test_io_params = {\n",
    "    'is_training': False,\n",
    "    'sloppy': False,\n",
    "    'shuffle': True,\n",
    "}\n",
    "test_tfrecords = test_data_files\n",
    "\n",
    "input_graph = tf.Graph()\n",
    "with input_graph.as_default():\n",
    "  mesh_load_op = create_input_from_dataset(\n",
    "      create_dataset_from_tfrecords, test_tfrecords, test_io_params)\n",
    "  with tf.Session() as sess:\n",
    "    test_mesh_data, test_labels = sess.run(mesh_load_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgRp-0fplMBD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Current Index: 0\n",
      ">>>> Vertices: 2652 / 2663\n",
      ">>>> Faces: 3999 / 4000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04aa079010b749d8b41655a6234a0c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(background='#dddddd', camera=PerspectiveCamera(aspect=1.5, children=(DirectionalLight(position=(-30.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0. 223. 291. 484. 471. 819. 272.  84.   4.   2.]\n"
     ]
    }
   ],
   "source": [
    "if 'cur_idx' not in locals() and 'cur_idx' not in globals():\n",
    "  cur_idx = 0\n",
    "    \n",
    "if cur_idx >= test_mesh_data['num_vertices'].shape[0]:\n",
    "  cur_idx = 0\n",
    "\n",
    "print(\">>> Current Index: %d\" % cur_idx)\n",
    "print(\">>>> Vertices: %d / %d\" % (test_mesh_data['num_vertices'][cur_idx], test_mesh_data[\"vertices\"][cur_idx].shape[0]))\n",
    "print(\">>>> Faces: %d / %d\" % (test_mesh_data[\"num_triangles\"][cur_idx], test_mesh_data[\"triangles\"][cur_idx].shape[0]))\n",
    "\n",
    "input_mesh_data = {\n",
    "    'vertices': test_mesh_data['vertices'][cur_idx],\n",
    "    'faces': test_mesh_data['triangles'][cur_idx],\n",
    "    'vertex_colors': mesh_viewer.SEGMENTATION_COLORMAP[test_labels[cur_idx]],\n",
    "}\n",
    "display_mesh(input_mesh_data)\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices=test_mesh_data['vertices'][cur_idx][:test_mesh_data['num_vertices'][cur_idx]],\n",
    "                       faces=test_mesh_data['triangles'][cur_idx][:test_mesh_data['num_triangles'][cur_idx]])\n",
    "neighbor_num = [len(v) for v in mesh.vertex_neighbors]\n",
    "hist, bins, _ = plt.hist(neighbor_num, bins=range(12), alpha=0.7, rwidth=0.75)  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram of count of neighbors\")\n",
    "plt.show()\n",
    "\n",
    "# hist, bins = np.histogram(neighbor_num, bins=range(12))\n",
    "print(hist)\n",
    "\n",
    "cur_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqV6vkCkWB7J"
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "Given a mesh with V vertices and D-dimensional per-vertex input features (e.g.\n",
    "vertex position, normal), we would like to create a network capable of\n",
    "classifying each vertex to a part label. Lets first create a mesh encoder that\n",
    "encodes each vertex in the mesh into C-dimensional logits, where C is the number\n",
    "of parts. First we use 1x1 convolutions to change input feature dimensions,\n",
    "followed by a sequence of feature steered graph convolutions and ReLU\n",
    "non-linearities, and finally 1x1 convolutions to logits, which are used for\n",
    "computing softmax cross entropy as described below.\n",
    "\n",
    "Note that this model does not use any form of pooling, which is outside the scope of this notebook.\n",
    "\n",
    "![](https://storage.googleapis.com/tensorflow-graphics/notebooks/mesh_segmentation/mesh_segmentation_model_def.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQVeuGazM0LK"
   },
   "outputs": [],
   "source": [
    "MODEL_PARAMS = {\n",
    "    'num_filters': 8,\n",
    "    'num_classes': 2,\n",
    "    'encoder_filter_dims': [32, 64, 128],\n",
    "    \n",
    "    # Adam Optimizer\n",
    "    'learning_rate': 0.001,\n",
    "    'beta': 0.9,\n",
    "    'adam_epsilon': 1e-08\n",
    "}\n",
    "\n",
    "\n",
    "def mesh_encoder(batch_mesh_data, num_filters, output_dim, conv_layer_dims):\n",
    "  \"\"\"A mesh encoder using feature steered graph convolutions.\n",
    "\n",
    "    The shorthands used below are\n",
    "      `B`: Batch size.\n",
    "      `V`: The maximum number of vertices over all meshes in the batch.\n",
    "      `D`: The number of dimensions of input vertex features, D=3 if vertex\n",
    "        positions are used as features.\n",
    "\n",
    "  Args:\n",
    "    batch_mesh_data: A mesh_data dict with following keys\n",
    "      'vertices': A [B, V, D] `float32` tensor of vertex features, possibly\n",
    "        0-padded.\n",
    "      'neighbors': A [B, V, V] `float32` sparse tensor of edge weights.\n",
    "      'num_vertices': A [B] `int32` tensor of number of vertices per mesh.\n",
    "    num_filters: The number of weight matrices to be used in feature steered\n",
    "      graph conv.\n",
    "    output_dim: A dimension of output per vertex features.\n",
    "    conv_layer_dims: A list of dimensions used in graph convolution layers.\n",
    "\n",
    "  Returns:\n",
    "    vertex_features: A [B, V, output_dim] `float32` tensor of per vertex\n",
    "      features.\n",
    "  \"\"\"\n",
    "  batch_vertices = batch_mesh_data['vertices']\n",
    "\n",
    "  # Linear: N x D --> N x 16.\n",
    "  vertex_features = tf.keras.layers.Conv1D(16, 1, name='lin16')(batch_vertices)\n",
    "\n",
    "  # graph convolution layers\n",
    "  for dim in conv_layer_dims:\n",
    "    with tf.variable_scope('conv_%d' % dim):\n",
    "      vertex_features = graph_conv.feature_steered_convolution_layer(\n",
    "          vertex_features,\n",
    "          batch_mesh_data['neighbors'],\n",
    "          batch_mesh_data['num_vertices'],\n",
    "          num_weight_matrices=num_filters,\n",
    "          num_output_channels=dim)\n",
    "    vertex_features = tf.nn.relu(vertex_features)\n",
    "\n",
    "  # Linear: N x 128 --> N x 256.\n",
    "  vertex_features = tf.keras.layers.Conv1D(\n",
    "      256, 1, name='lin256')(\n",
    "          vertex_features)\n",
    "  vertex_features = tf.nn.relu(vertex_features)\n",
    "\n",
    "  # Linear: N x 256 --> N x output_dim.\n",
    "  vertex_features = tf.keras.layers.Conv1D(\n",
    "      output_dim, 1, name='lin_output')(\n",
    "          vertex_features)\n",
    "\n",
    "  return vertex_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6c2pz4r_79F_"
   },
   "source": [
    "Given a mesh encoder, let's define a model_fn for a custom\n",
    "[tf.Estimator](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator)\n",
    "for vertex classification using softmax cross entropy loss. A tf.Estimator model_fn returns the ops necessary to perform training, evaluation, or predictions given inputs and a number of other parameters. Recall that the\n",
    "vertex tensor may be zero-padded (see Dataset Pipeline above), hence we must mask out the contribution from the padded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WE-cuv0i78ak"
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "  \"\"\"Returns a mesh segmentation model_fn for use with tf.Estimator.\"\"\"\n",
    "  logits = mesh_encoder(features, params['num_filters'], params['num_classes'],\n",
    "                        params['encoder_filter_dims'])\n",
    "  predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "  outputs = {\n",
    "      'vertices': features['vertices'],\n",
    "      'triangles': features['triangles'],\n",
    "      'num_vertices': features['num_vertices'],\n",
    "      'num_triangles': features['num_triangles'],\n",
    "      'predictions': predictions\n",
    "  }\n",
    "  # For predictions, return the outputs.\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    outputs['labels'] = features['labels']\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=outputs)\n",
    "  # Loss\n",
    "  # Weight the losses by masking out padded vertices/labels.\n",
    "  vertex_ragged_sizes = features['num_vertices']\n",
    "  mask = tf.sequence_mask(vertex_ragged_sizes, tf.shape(labels)[-1])\n",
    "  loss_weights = tf.cast(mask, dtype=tf.float32)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "      logits=logits, labels=labels, weights=loss_weights)\n",
    "  # For training, build the optimizer.\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        beta1=params['beta'],\n",
    "        epsilon=params['adam_epsilon'])\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "      train_op = optimizer.minimize(\n",
    "          loss=loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # For eval, return eval metrics.\n",
    "  eval_ops = {\n",
    "      'mean_loss':\n",
    "          tf.metrics.mean(loss),\n",
    "      'accuracy':\n",
    "          tf.metrics.accuracy(\n",
    "              labels=labels, predictions=predictions, weights=loss_weights)\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94FICCro_dLV"
   },
   "source": [
    "## Test model & visualize results\n",
    "\n",
    "Now that we have defined the model, let's load the weights from the trained model downloaded above and use tf.Estimator.predict to predict the part labels for meshes in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Olj5zIkg72FK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dancer_test_sequence.tfrecords']\n"
     ]
    }
   ],
   "source": [
    "test_io_params = {\n",
    "    'is_training': False,\n",
    "    'sloppy': False,\n",
    "    'shuffle': True,\n",
    "    'repeat': False,\n",
    "    'batch_size': 2\n",
    "}\n",
    "test_tfrecords = test_data_files\n",
    "print(test_tfrecords)\n",
    "\n",
    "def predict_fn():\n",
    "  return create_input_from_dataset(create_dataset_from_tfrecords,\n",
    "                                          test_tfrecords,\n",
    "                                          test_io_params)\n",
    "\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                   model_dir=local_model_dir,\n",
    "                                   params=MODEL_PARAMS)\n",
    "test_predictions = estimator.predict(input_fn=predict_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IO1VmbL087xf"
   },
   "source": [
    "Run the following cell repeatedly to cycle through the meshes in the test sequence. The left view shows the input mesh, and the right view shows the predicted part labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xuoVe70D5PAF"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7692ac66f9d4b25aae6ec17ec60c841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(background='#dddddd', camera=PerspectiveCamera(aspect=1.5, children=(DirectionalLight(position=(-30.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9581de21a6094d1b957f6a9608bfa3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(background='#dddddd', camera=PerspectiveCamera(aspect=1.5, children=(DirectionalLight(position=(-30.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "prediction = next(test_predictions)\n",
    "# print(prediction[\"extra\"])\n",
    "input_mesh_data = {\n",
    "    'vertices': prediction['vertices'],\n",
    "    'faces': prediction['triangles'],\n",
    "}\n",
    "predicted_mesh_data = {\n",
    "    'vertices': prediction['vertices'],\n",
    "    'faces': prediction['triangles'],\n",
    "    'vertex_colors': mesh_viewer.SEGMENTATION_COLORMAP[prediction['predictions']],\n",
    "}\n",
    "\n",
    "display_mesh(input_mesh_data)\n",
    "display_mesh(predicted_mesh_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on psbCup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca4826678b54c7e886ae88642e38dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(background='#dddddd', camera=PerspectiveCamera(aspect=1.5, children=(DirectionalLight(position=(-30.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_io_params = {\n",
    "    'is_training': False,\n",
    "    'sloppy': False,\n",
    "    'shuffle': True,\n",
    "}\n",
    "test_tfrecords = ['psbCup.train.tfrecords', 'psbCup.test.tfrecords']\n",
    "\n",
    "input_graph = tf.Graph()\n",
    "with input_graph.as_default():\n",
    "  mesh_load_op = dataio.create_input_from_dataset(\n",
    "      dataio.create_dataset_from_tfrecords, test_tfrecords, test_io_params)\n",
    "  with tf.Session() as sess:\n",
    "    test_mesh_data, test_labels = sess.run(mesh_load_op)\n",
    "    \n",
    "input_mesh_data = {\n",
    "    'vertices': test_mesh_data['vertices'][0],\n",
    "    'faces': test_mesh_data['triangles'][0],\n",
    "    'vertex_colors': mesh_viewer.SEGMENTATION_COLORMAP[test_labels[0]],\n",
    "}\n",
    "display_mesh(input_mesh_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Cup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0814 21:28:03.297755 4694070720 estimator.py:1790] Using default config.\n",
      "I0814 21:28:03.300096 4694070720 estimator.py:209] Using config: {'_model_dir': './psbCup_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x140577ba8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0814 21:28:03.490075 4694070720 estimator.py:1145] Calling model_fn.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "I0814 21:28:05.491243 4694070720 estimator.py:1147] Done calling model_fn.\n",
      "I0814 21:28:05.492932 4694070720 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0814 21:28:05.651808 4694070720 monitored_session.py:240] Graph was finalized.\n",
      "I0814 21:28:05.655787 4694070720 saver.py:1280] Restoring parameters from ./psbCup_model/model.ckpt-325\n",
      "I0814 21:28:05.855672 4694070720 session_manager.py:500] Running local_init_op.\n",
      "I0814 21:28:05.898299 4694070720 session_manager.py:502] Done running local_init_op.\n",
      "I0814 21:28:07.146726 4694070720 basic_session_run_hooks.py:606] Saving checkpoints for 325 into ./psbCup_model/model.ckpt.\n",
      "I0814 21:28:29.460612 4694070720 basic_session_run_hooks.py:262] loss = 0.23438218, step = 326\n",
      "I0814 21:34:27.702757 4694070720 basic_session_run_hooks.py:692] global_step/sec: 0.279141\n",
      "I0814 21:34:27.711185 4694070720 basic_session_run_hooks.py:260] loss = 0.18572834, step = 426 (358.251 sec)\n",
      "I0814 21:38:08.647348 4694070720 basic_session_run_hooks.py:606] Saving checkpoints for 488 into ./psbCup_model/model.ckpt.\n",
      "I0814 21:40:21.228624 4694070720 basic_session_run_hooks.py:692] global_step/sec: 0.282864\n",
      "I0814 21:40:21.229961 4694070720 basic_session_run_hooks.py:260] loss = 0.14246985, step = 526 (353.519 sec)\n",
      "I0814 21:46:10.666975 4694070720 basic_session_run_hooks.py:692] global_step/sec: 0.286173\n",
      "I0814 21:46:10.669770 4694070720 basic_session_run_hooks.py:260] loss = 0.15999517, step = 626 (349.440 sec)\n",
      "I0814 21:48:09.813242 4694070720 basic_session_run_hooks.py:606] Saving checkpoints for 660 into ./psbCup_model/model.ckpt.\n",
      "I0814 21:52:00.743397 4694070720 basic_session_run_hooks.py:692] global_step/sec: 0.285652\n",
      "I0814 21:52:00.746966 4694070720 basic_session_run_hooks.py:260] loss = 0.1579118, step = 726 (350.077 sec)\n",
      "I0814 21:57:50.171864 4694070720 basic_session_run_hooks.py:692] global_step/sec: 0.286181\n",
      "I0814 21:57:50.174932 4694070720 basic_session_run_hooks.py:260] loss = 0.09975349, step = 826 (349.428 sec)\n",
      "I0814 21:58:11.181942 4694070720 basic_session_run_hooks.py:606] Saving checkpoints for 832 into ./psbCup_model/model.ckpt.\n",
      "I0814 22:03:39.116549 4694070720 basic_session_run_hooks.py:692] global_step/sec: 0.286578\n",
      "I0814 22:03:39.124793 4694070720 basic_session_run_hooks.py:260] loss = 0.15937401, step = 926 (348.950 sec)\n",
      "I0814 22:08:13.590006 4694070720 basic_session_run_hooks.py:606] Saving checkpoints for 1004 into ./psbCup_model/model.ckpt.\n",
      "I0814 22:09:30.447340 4694070720 basic_session_run_hooks.py:692] global_step/sec: 0.284632\n",
      "I0814 22:09:30.448647 4694070720 basic_session_run_hooks.py:260] loss = 0.12819946, step = 1026 (351.324 sec)\n",
      "I0814 22:15:28.622743 4694070720 basic_session_run_hooks.py:692] global_step/sec: 0.279194\n",
      "I0814 22:15:28.631386 4694070720 basic_session_run_hooks.py:260] loss = 0.11517489, step = 1126 (358.183 sec)\n",
      "I0814 22:18:13.771713 4694070720 basic_session_run_hooks.py:606] Saving checkpoints for 1171 into ./psbCup_model/model.ckpt.\n",
      "I0814 22:21:41.895384 4694070720 basic_session_run_hooks.py:692] global_step/sec: 0.267901\n",
      "I0814 22:21:41.904062 4694070720 basic_session_run_hooks.py:260] loss = 0.12708351, step = 1226 (373.273 sec)\n",
      "I0814 22:28:01.722735 4694070720 basic_session_run_hooks.py:606] Saving checkpoints for 1325 into ./psbCup_model/model.ckpt.\n",
      "I0814 22:28:02.336210 4694070720 estimator.py:368] Loss for final step: 0.12955303.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x140577748>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_io_params = {\n",
    "    'is_training': True,\n",
    "    'sloppy': False,\n",
    "    'shuffle': True,\n",
    "    'repeat': True,\n",
    "    'batch_size': 5\n",
    "}\n",
    "train_tfrecords = ['psbCup.train.tfrecords']\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def train_fn():\n",
    "  return dataio.create_input_from_dataset(dataio.create_dataset_from_tfrecords,\n",
    "                                          train_tfrecords,\n",
    "                                          train_io_params)\n",
    "local_model_dir = \"./psbCup_model\"\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                   model_dir=local_model_dir,\n",
    "                                   params=MODEL_PARAMS)\n",
    "estimator.train(input_fn=train_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 11:15:52.546389 4694070720 estimator.py:1790] Using default config.\n",
      "I0815 11:15:52.549541 4694070720 estimator.py:209] Using config: {'_model_dir': './psbCup_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13def5ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "test_io_params = {\n",
    "    'is_training': False,\n",
    "    'sloppy': False,\n",
    "    'shuffle': True,\n",
    "}\n",
    "test_tfrecords = ['psbCup.test.tfrecords']\n",
    "\n",
    "def predict_fn():\n",
    "  return dataio.create_input_from_dataset(dataio.create_dataset_from_tfrecords,\n",
    "                                          test_tfrecords,\n",
    "                                          test_io_params)\n",
    "local_model_dir = \"./psbCup_model\"\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                   model_dir=local_model_dir,\n",
    "                                   params=MODEL_PARAMS)\n",
    "test_predictions = estimator.predict(input_fn=predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 11:15:53.660799 4694070720 estimator.py:1145] Calling model_fn.\n",
      "I0815 11:15:54.147382 4694070720 estimator.py:1147] Done calling model_fn.\n",
      "I0815 11:15:54.236064 4694070720 monitored_session.py:240] Graph was finalized.\n",
      "I0815 11:15:54.241089 4694070720 saver.py:1280] Restoring parameters from ./psbCup_model/model.ckpt-1325\n",
      "I0815 11:15:54.421657 4694070720 session_manager.py:500] Running local_init_op.\n",
      "I0815 11:15:54.448805 4694070720 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f03284af28b4f2eabe641b3f1e2b1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(background='#dddddd', camera=PerspectiveCamera(aspect=1.5, children=(DirectionalLight(position=(-30.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916579e471dc420fa49615132e23ab7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(background='#dddddd', camera=PerspectiveCamera(aspect=1.5, children=(DirectionalLight(position=(-30.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = next(test_predictions)\n",
    "# print(prediction[\"extra\"])\n",
    "input_mesh_data = {\n",
    "    'vertices': prediction['vertices'],\n",
    "    'faces': prediction['triangles'],\n",
    "}\n",
    "predicted_mesh_data = {\n",
    "    'vertices': prediction['vertices'],\n",
    "    'faces': prediction['triangles'],\n",
    "    'vertex_colors': mesh_viewer.SEGMENTATION_COLORMAP[prediction['predictions']],\n",
    "}\n",
    "\n",
    "display_mesh(input_mesh_data)\n",
    "display_mesh(predicted_mesh_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Our Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vYRrD4-POtR"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a15c4774ab45418448e3cf0b53f92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(background='#dddddd', camera=PerspectiveCamera(aspect=1.5, children=(DirectionalLight(position=(-30.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh = trimesh.load(\"../meshes/f_c_10412256613_model.obj\")\n",
    "mesh_data = {\n",
    "    'vertices': mesh.vertices,\n",
    "    'faces': mesh.faces\n",
    "}\n",
    "display_mesh(mesh_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xYrAxxPa5iE"
   },
   "outputs": [],
   "source": [
    "mean_center = True\n",
    "\n",
    "def mesh_to_features(mesh):\n",
    "  labels = tf.zeros(mesh.vertices.shape[0], tf.int32)\n",
    "  vertices = tf.convert_to_tensor(mesh.vertices, dtype=tf.float32)\n",
    "  num_vertices = tf.shape(input=vertices)[0]\n",
    "  if mean_center:\n",
    "    vertices = vertices - tf.reduce_mean(input_tensor=vertices, axis=0, keepdims=True)\n",
    "\n",
    "  triangles = tf.convert_to_tensor(mesh.faces, dtype=tf.int32)\n",
    "  num_triangles = tf.shape(input=triangles)[0]\n",
    "\n",
    "  edges, edge_weights = tf.py_function(\n",
    "    func=lambda t: dataio.get_weighted_edges(t.numpy()),\n",
    "    inp=[triangles],\n",
    "    Tout=[tf.int32, tf.float32]\n",
    "  )\n",
    "  num_edges = tf.shape(input=edges)[0]\n",
    "\n",
    "  vertices=tf.reshape(vertices, [1, -1, 3])\n",
    "  triangles=tf.reshape(triangles, [1, -1, 3])\n",
    "  edges=tf.reshape(edges, [1, -1, 2])\n",
    "  edge_weights=tf.reshape(edge_weights, [1, -1])\n",
    "  labels = tf.reshape(labels, [1, -1])\n",
    "  \n",
    "  num_vertices = tf.reshape(num_vertices, [1])\n",
    "  num_triangles = tf.reshape(num_triangles, [1])\n",
    "  num_edges = tf.reshape(num_edges, [1])\n",
    "\n",
    "#     paddings = tf.constant([[0, 2667 - vertices.shape[0]], [0, 0]])\n",
    "#     vertices = tf.pad(vertices, paddings, \"CONSTANT\")\n",
    "\n",
    "#     paddings = tf.constant([[0, 4000 - triangles.shape[0]], [0, 0]])\n",
    "#     triangles = tf.pad(vertices, paddings, \"CONSTANT\")\n",
    "\n",
    "#     paddings = tf.constant([[0, 15877 - edges.shape[0]], [0, 0]])\n",
    "#     edges = tf.pad(edges, paddings, \"CONSTANT\")\n",
    "\n",
    "#     paddings = tf.constant([[0, 15877 - weights.shape[0]], [0, 0]])\n",
    "#     weights = tf.pad(weights, paddings, \"CONSTANT\")\n",
    "\n",
    "  neighbors = dataio.adjacency_from_edges(\n",
    "    edges,\n",
    "    edge_weights,\n",
    "    num_edges,\n",
    "    num_vertices\n",
    "  )\n",
    "\n",
    "\n",
    "  features = dict(\n",
    "    vertices=vertices,\n",
    "    triangles=triangles,\n",
    "    neighbors=neighbors,\n",
    "    num_triangles=num_triangles,\n",
    "    num_vertices=num_vertices,\n",
    "    labels=labels\n",
    "  )\n",
    "\n",
    "\n",
    "#   return labels, vertices, triangles, edges, edge_weights, neighbors\n",
    "  return features, labels\n",
    "\n",
    "# input_graph = tf.Graph()\n",
    "# with input_graph.as_default():\n",
    "#   with tf.Session() as sess:\n",
    "#     mesh_op = handle(mesh)\n",
    "#     labels, vertices, triangles, edges, weights, neighbors = sess.run(mesh_op)\n",
    "\n",
    "#     print(vertices.shape)\n",
    "#     print(edges.shape)\n",
    "#     print(weights.shape)\n",
    "#     print(neighbors)\n",
    "    \n",
    "# mesh_data = {\n",
    "#     'vertices': vertices,\n",
    "#     'faces': triangles\n",
    "# }\n",
    "# input_viewer = mesh_viewer.Viewer(mesh_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lWNHEaNuIyp"
   },
   "outputs": [],
   "source": [
    "def my_predict_fn():\n",
    "  return mesh_to_features(mesh)\n",
    "\n",
    "\n",
    "my_estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                   model_dir=local_model_dir,\n",
    "                                   params=MODEL_PARAMS)\n",
    "my_test_predictions = my_estimator.predict(input_fn=my_predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VUHIBHuudHG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0808 17:41:16.844424 4485752256 estimator.py:1000] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Vertices: 67149 / 67149\n",
      ">>>> Faces: 100000 / 100000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a06fef75c1b442dad274cbf07ad33a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(background='#dddddd', camera=PerspectiveCamera(aspect=1.5, children=(DirectionalLight(position=(-30.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe53f0220724f05a553e9c8cc8e2a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(background='#dddddd', camera=PerspectiveCamera(aspect=1.5, children=(DirectionalLight(position=(-30.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = next(my_test_predictions)\n",
    "print(\">>>> Vertices: %d / %d\" % (prediction[\"num_vertices\"], prediction[\"vertices\"].shape[0]))\n",
    "print(\">>>> Faces: %d / %d\" % (prediction[\"num_triangles\"], prediction[\"triangles\"].shape[0]))\n",
    "\n",
    "input_mesh_data = {\n",
    "    'vertices': prediction['vertices'],\n",
    "    'faces': prediction['triangles'],\n",
    "}\n",
    "predicted_mesh_data = {\n",
    "    'vertices': prediction['vertices'],\n",
    "    'faces': prediction['triangles'],\n",
    "    'vertex_colors': mesh_viewer.SEGMENTATION_COLORMAP[prediction['predictions']],\n",
    "}\n",
    "\n",
    "display_mesh(input_mesh_data)\n",
    "display_mesh(predicted_mesh_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of mesh_segmentation_demo.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
